{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcsWFgvHCdVz"
      },
      "outputs": [],
      "source": [
        "! pip install cltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cltk import NLP"
      ],
      "metadata": {
        "id": "Lw1JtwynCg2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cltk_nlp = NLP(language=\"gmh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baszRdCSFQtB",
        "outputId": "235beb28-ad1a-4847-99dd-db770a8b6531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚Äéê§Ä CLTK version '1.2.1'. When using the CLTK in research, please cite: https://aclanthology.org/2021.acl-demo.3/\n",
            "\n",
            "Pipeline for language 'Middle High German' (ISO: 'gmh'): `MiddleHighGermanTokenizationProcess`, `StopsProcess`.\n",
            "\n",
            "\n",
            "‚∏é To suppress these messages, instantiate ``NLP()`` with ``suppress_banner=True``.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('NIBELUNG.txt', 'r', encoding='utf-8') as f:\n",
        "  txt = f.read()"
      ],
      "metadata": {
        "id": "8XhMROu6HKuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cltk_doc = cltk_nlp.analyze(text=txt)"
      ],
      "metadata": {
        "id": "2MGRNKdDG6r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dictionary(string_list):\n",
        "    result_dict = {}\n",
        "    current_key = None\n",
        "\n",
        "    for string in string_list:\n",
        "        if string.isdigit():\n",
        "            current_key = string\n",
        "            result_dict[current_key] = []\n",
        "        elif current_key:\n",
        "            result_dict[current_key].append(string)\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "input_list = cltk_doc.tokens\n",
        "\n",
        "result = create_dictionary(input_list)"
      ],
      "metadata": {
        "id": "HgjvAi3kHt2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "one = pd.read_csv('ner-dataset.csv')\n",
        "\n",
        "names_person = []\n",
        "names_place = []\n",
        "names_group = []\n",
        "\n",
        "for index, row in one.iterrows():\n",
        "    tokens = str(row['tokens'])\n",
        "    category = row['category']\n",
        "    if pd.notna(tokens):\n",
        "        tokens = tokens.split(':')\n",
        "        for token in tokens:\n",
        "            if category == 'PERSON':\n",
        "                names_person.append(token)\n",
        "            elif category == 'PLACE':\n",
        "                names_place.append(token)\n",
        "            elif category == 'GROUP':\n",
        "                names_group.append(token)\n",
        "\n",
        "names_person = list(set(names_person))\n",
        "names_place = list(set(names_place))\n",
        "names_group = list(set(names_group))"
      ],
      "metadata": {
        "id": "QiYgOFjPvGwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# result.values()"
      ],
      "metadata": {
        "id": "GXDe1jMotlDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tag(name):\n",
        "  if name in names_person:\n",
        "    return 1\n",
        "  elif name in names_place:\n",
        "    return 5\n",
        "  elif name in names_group:\n",
        "    return 3\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "two = pd.DataFrame(columns=['tokens', 'ner_tags', 'lang'])\n",
        "two['tokens'] = list(result.values())\n",
        "two['ner_tags'] = two['tokens'].apply(lambda x: [get_tag(name) for name in x])\n",
        "# two['tokens'] = two['tokens'].apply(lambda x: [item.lower() for item in x])\n",
        "two['lang'] = 'de'"
      ],
      "metadata": {
        "id": "eZjsyQcb3rrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "two=two.sample(frac=1)\n",
        "two.to_pickle(\"ner_dataset.pkl\")"
      ],
      "metadata": {
        "id": "ZJ5mepcwI206"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# two.to_csv('ner-nibelung.csv', index=False, header=True)"
      ],
      "metadata": {
        "id": "kiqRIYKtP-ra"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}